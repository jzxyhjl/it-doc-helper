# 向量化服务替代方案

## 一、问题背景

DeepSeek 目前不提供 Embeddings API，使用 Chat API 作为降级方案存在以下问题：
- **成本高**：Chat API 调用费用较高
- **速度慢**：需要生成大量文本，响应时间长
- **质量不稳定**：向量质量可能不如专门的 Embeddings API
- **影响用户体验**：处理时间长，可能超时

## 二、替代方案

### 方案1：本地嵌入模型（sentence-transformers）⭐ **推荐**

#### 优点
- ✅ **完全本地化**：不依赖外部 API，无网络延迟
- ✅ **成本低**：无 API 调用费用
- ✅ **速度快**：本地计算，响应迅速
- ✅ **质量好**：专门用于嵌入任务，质量稳定
- ✅ **支持中文**：使用多语言模型，支持中文优化
- ✅ **适合 Docker 部署**：模型可打包到镜像中

#### 缺点
- ⚠️ **镜像体积增大**：模型文件较大（约 100-500MB）
- ⚠️ **首次加载慢**：需要下载模型文件（可通过预加载解决）

#### 实现方式
使用 `sentence-transformers` 库，支持多种预训练模型：
- `paraphrase-multilingual-MiniLM-L12-v2`：多语言模型，384维
- `text2vec-base-chinese`：中文优化模型，768维
- 其他模型可根据需求选择

#### 配置
```env
USE_LOCAL_EMBEDDING=true  # 默认启用
EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```

---

### 方案2：其他云服务 Embeddings API

#### OpenAI Embeddings API
- **优点**：质量高，1536维，稳定可靠
- **缺点**：需要 OpenAI API Key，有调用费用
- **配置**：
  ```env
  OPENAI_API_KEY=your_openai_key
  USE_LOCAL_EMBEDDING=false
  ```

#### 其他服务
- 百度文心一言 Embeddings
- 阿里云 Embeddings
- 腾讯云 Embeddings

---

### 方案3：Chat API 降级（最后备选）

仅在以上方案都不可用时使用，会记录警告日志。

---

## 三、实施优先级

1. **优先**：本地嵌入模型（方案1）
2. **备选**：其他云服务 Embeddings API（方案2）
3. **最后**：Chat API 降级（方案3）

## 四、技术实现

### 代码结构
```python
class EmbeddingService:
    async def generate_embedding(self, text: str) -> Optional[List[float]]:
        # 方案1：本地嵌入模型（优先）
        if self._use_local_model:
            return await self._generate_via_local_model(text)
        
        # 方案2：DeepSeek Embeddings API
        embedding = await self._generate_via_embeddings_api(text)
        if embedding:
            return embedding
        
        # 方案3：其他云服务 Embeddings API
        embedding = await self._generate_via_other_embeddings_api(text)
        if embedding:
            return embedding
        
        # 方案4：Chat API 降级（最后备选）
        logger.warning("降级使用Chat API（可能影响用户体验）")
        return await self._generate_via_chat_api(text)
```

### 维度处理
- 本地模型可能返回不同维度（如 384、768 维）
- 自动调整到 1536 维：
  - 如果维度 > 1536：截断
  - 如果维度 < 1536：零填充

## 五、配置说明

### 环境变量（.env 文件）

```env
# 本地嵌入模型配置（推荐）
USE_LOCAL_EMBEDDING=true
EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# OpenAI Embeddings API（可选）
OPENAI_API_KEY=your_openai_key

# DeepSeek API（用于其他功能）
DEEPSEEK_API_KEY=your_deepseek_key
```

### 配置优先级
1. `USE_LOCAL_EMBEDDING=true` → 使用本地模型
2. `OPENAI_API_KEY` 存在 → 使用 OpenAI Embeddings API
3. `DEEPSEEK_API_KEY` 存在 → 尝试 DeepSeek Embeddings API
4. 最后 → Chat API 降级

## 六、性能对比

| 方案 | 速度 | 成本 | 质量 | 稳定性 |
|------|------|------|------|--------|
| 本地嵌入模型 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| OpenAI Embeddings | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| Chat API 降级 | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |

## 七、部署注意事项

### Docker 镜像
- 需要安装 `sentence-transformers` 和 `torch`
- 模型文件会在首次运行时自动下载
- 建议在构建时预下载模型，减少首次启动时间

### 模型选择建议
- **中文文档为主**：使用 `text2vec-base-chinese` 或 `paraphrase-multilingual-MiniLM-L12-v2`
- **多语言支持**：使用 `paraphrase-multilingual-MiniLM-L12-v2`
- **性能优先**：使用较小的模型（如 MiniLM）
- **质量优先**：使用较大的模型（如 BERT-base）

## 八、测试建议

1. **功能测试**：验证向量生成是否正常
2. **性能测试**：对比不同方案的响应时间
3. **质量测试**：验证向量相似度搜索的准确性
4. **稳定性测试**：长时间运行，验证内存和性能

---

**文档版本**: v1.0  
**创建时间**: 2025-12-10  
**最后更新**: 2025-12-10

